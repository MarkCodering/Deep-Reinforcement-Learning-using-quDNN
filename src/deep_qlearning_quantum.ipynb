{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Qiskit is installed in an invalid environment that has both Qiskit >=1.0 and an earlier version. You should create a new virtual environment, and ensure that you do not mix dependencies between Qiskit <1.0 and >=1.0. Any packages that depend on 'qiskit-terra' are not compatible with Qiskit 1.0 and will need to be updated. Qiskit unfortunately cannot enforce this requirement during environment resolution. See https://qisk.it/packaging-1-0 for more detail.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Linear\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mqiskit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QuantumCircuit\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mqiskit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m algorithm_globals\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mqiskit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcircuit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Parameter\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/qiskit/__init__.py:36\u001b[0m\n\u001b[1;32m     34\u001b[0m     _suppress_error \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQISKIT_SUPPRESS_1_0_IMPORT_ERROR\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _suppress_error \u001b[38;5;129;01mand\u001b[39;00m _has_tools:\n\u001b[0;32m---> 36\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     37\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQiskit is installed in an invalid environment that has both Qiskit >=1.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and an earlier version.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     39\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m You should create a new virtual environment, and ensure that you do not mix\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     40\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m dependencies between Qiskit <1.0 and >=1.0.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     41\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Any packages that depend on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqiskit-terra\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m are not compatible with Qiskit 1.0 and\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     42\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m will need to be updated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     43\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Qiskit unfortunately cannot enforce this requirement during environment resolution.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     44\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m See https://qisk.it/packaging-1-0 for more detail.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     45\u001b[0m         )\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mqiskit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_accelerate\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Globally define compiled submodules. The normal import mechanism will not find compiled submodules\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# in _accelerate because it relies on file paths, but PyO3 generates only one shared library file.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# We manually define them on import so people can directly import qiskit._accelerate.* submodules\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# and not have to rely on attribute access.  No action needed for top-level extension packages.\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Qiskit is installed in an invalid environment that has both Qiskit >=1.0 and an earlier version. You should create a new virtual environment, and ensure that you do not mix dependencies between Qiskit <1.0 and >=1.0. Any packages that depend on 'qiskit-terra' are not compatible with Qiskit 1.0 and will need to be updated. Qiskit unfortunately cannot enforce this requirement during environment resolution. See https://qisk.it/packaging-1-0 for more detail."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.special as sp\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import collections\n",
    "\n",
    "# Necessary imports\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import Linear\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.utils import algorithm_globals\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit.circuit.library import RealAmplitudes, ZFeatureMap\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduce experience replay.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = collections.namedtuple('Experience',\n",
    "                                    field_names=['state', 'action',\n",
    "                                                 'next_state', 'reward',\n",
    "                                                 'is_game_on'])\n",
    "\n",
    "class ExperienceReplay:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = collections.deque(maxlen=capacity)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "    def push(self, transition):\n",
    "        self.memory.append(transition)\n",
    "\n",
    "    def sample(self, batch_size, device = 'cuda'):\n",
    "        indices = np.random.choice(len(self.memory), batch_size, replace = False)\n",
    "        \n",
    "        states, actions, next_states, rewards, isgameon = zip(*[self.memory[idx] \n",
    "                                                                for idx in indices])\n",
    "        \n",
    "        return torch.Tensor(states).type(torch.float).to(device), \\\n",
    "               torch.Tensor(actions).type(torch.long).to(device), \\\n",
    "               torch.Tensor(next_states).to(device), \\\n",
    "               torch.Tensor(rewards).to(device), torch.tensor(isgameon).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Networks definition.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QNN Training Parameters:  4\n"
     ]
    }
   ],
   "source": [
    "num_qubits = 2\n",
    "\n",
    "def create_qnn():\n",
    "    qc = QuantumCircuit(num_qubits)\n",
    "    feature_map = ZFeatureMap(num_qubits)\n",
    "    ansatz = RealAmplitudes(num_qubits=num_qubits, reps=1)\n",
    "\n",
    "    qc.compose(feature_map, inplace=True)\n",
    "    qc.compose(ansatz, inplace=True)\n",
    "\n",
    "    # REMEMBER TO SET input_gradients=True FOR ENABLING HYBRID GRADIENT BACKPROP\n",
    "    qnn = SamplerQNN(\n",
    "        circuit=qc,\n",
    "        input_params=feature_map.parameters,\n",
    "        weight_params=ansatz.parameters,\n",
    "        input_gradients=True,\n",
    "    )\n",
    "    \n",
    "    return qnn\n",
    "\n",
    "qnn = create_qnn()\n",
    "print(\"QNN Training Parameters: \", qnn.num_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_nn(nn.Module):\n",
    "    \n",
    "    channels = [16, 32, 64]\n",
    "    kernels = [3, 3, 3]\n",
    "    strides = [1, 1, 1]\n",
    "    in_channels = 1\n",
    "    \n",
    "    def __init__(self, rows, cols, n_act):\n",
    "        super().__init__()\n",
    "        self.rows = rows\n",
    "        self.cols = cols\n",
    "\n",
    "        self.conv = nn.Sequential(nn.Conv2d(in_channels = self.in_channels,\n",
    "                                            out_channels = self.channels[0],\n",
    "                                            kernel_size = self.kernels[0],\n",
    "                                            stride = self.strides[0]),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Conv2d(in_channels = self.channels[0],\n",
    "                                            out_channels = self.channels[1],\n",
    "                                            kernel_size = self.kernels[1],\n",
    "                                            stride = self.strides[1]),\n",
    "                                  nn.ReLU()\n",
    "                                 )\n",
    "        \n",
    "        size_out_conv = self.get_conv_size(rows, cols)\n",
    "        self.linear = nn.Sequential(nn.Linear(size_out_conv, rows*cols*2),\n",
    "                                    nn.ReLU(),\n",
    "                                    TorchConnector(qnn),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(int(rows*cols/2), n_act),\n",
    "                                   )\n",
    "       \n",
    "    def forward(self, x):\n",
    "        x = x.view(len(x), self.in_channels, self.rows, self.cols)\n",
    "        out_conv = self.conv(x).view(len(x),-1)\n",
    "        out_lin = self.linear(out_conv)\n",
    "        return out_lin\n",
    "    \n",
    "    def get_conv_size(self, x, y):\n",
    "        out_conv = self.conv(torch.zeros(1,self.in_channels, x, y))\n",
    "        return int(np.prod(out_conv.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Qloss(batch, net, gamma=0.99, device=\"cuda\"):\n",
    "    states, actions, next_states, rewards, _ = batch\n",
    "    lbatch = len(states)\n",
    "    state_action_values = net(states.view(lbatch,-1))\n",
    "    state_action_values = state_action_values.gather(1, actions.unsqueeze(-1))\n",
    "    state_action_values = state_action_values.squeeze(-1)\n",
    "    \n",
    "    next_state_values = net(next_states.view(lbatch, -1))\n",
    "    next_state_values = next_state_values.max(1)[0]\n",
    "    \n",
    "    next_state_values = next_state_values.detach()\n",
    "    expected_state_action_values = next_state_values * gamma + rewards\n",
    "    \n",
    "    return nn.MSELoss()(state_action_values, expected_state_action_values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import the maze and define the environment.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from environment import MazeEnvironment\n",
    "\n",
    "maze = np.load('./maze_generator/maze_10x10.npy')\n",
    "\n",
    "initial_position = [0,0]\n",
    "goal = [len(maze)-1, len(maze)-1]\n",
    "\n",
    "maze_env = MazeEnvironment(maze, initial_position, goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "maze_env.draw('./results/maze_10.pdf')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the agent and the buffer for experience replay.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_capacity = 10000\n",
    "buffer_start_size = 1000\n",
    "memory_buffer = ExperienceReplay(buffer_capacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent import Agent\n",
    "agent = Agent(maze = maze_env,\n",
    "              memory_buffer = memory_buffer,\n",
    "              use_softmax = True\n",
    "             )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Define the network.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m net \u001b[38;5;241m=\u001b[39m \u001b[43mconv_nn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmaze\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmaze\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(net\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/cuda/__init__.py:239\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "net = conv_nn(len(maze), len(maze), 4).to('cuda')\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 24\n",
    "gamma = 0.9\n",
    "\n",
    "net.to(device)\n",
    "print(\"Number of Trainable Parameters: \", sum(p.numel() for p in net.parameters() if p.requires_grad))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the epsilon profile and plot the resetting probability.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_epochs = 20000\n",
    "\n",
    "cutoff = 3000\n",
    "epsilon = np.exp(-np.arange(num_epochs)/(cutoff))\n",
    "epsilon[epsilon > epsilon[100*int(num_epochs/cutoff)]] = epsilon[100*int(num_epochs/cutoff)]\n",
    "plt.plot(epsilon, color = 'orangered', ls = '--')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Epsilon')\n",
    "plt.savefig('epsilon_profile.pdf', dpi = 300, bbox_inches = 'tight')\n",
    "plt.show()\n",
    "\n",
    "mp = []\n",
    "mpm = []\n",
    "reg = 200\n",
    "for e in epsilon:\n",
    "    a = agent.env.reset_policy(e)\n",
    "    mp.append(np.min(a))\n",
    "    mpm.append(np.max(a))\n",
    "\n",
    "plt.plot(epsilon/1.3, color = 'orangered', ls = '--', alpha = 0.5,\n",
    "         label= 'Epsilon profile (arbitrary units)')\n",
    "\n",
    "plt.plot(np.array(mpm)-np.array(mp), label = 'Probability difference', color = 'cornflowerblue')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel(r'max $p^r$ - min $p^r$')\n",
    "plt.legend()\n",
    "plt.savefig('reset_policy.pdf', dpi = 300, bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training the network.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_log = []\n",
    "best_loss = 1e5\n",
    "\n",
    "running_loss = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loss = 0\n",
    "    counter = 0\n",
    "    eps = epsilon[epoch]\n",
    "    \n",
    "    agent.isgameon = True\n",
    "    _ = agent.env.reset(eps)\n",
    "    \n",
    "    while agent.isgameon:\n",
    "        agent.make_a_move(net, eps)\n",
    "        counter += 1\n",
    "        \n",
    "        if len(agent.buffer) < buffer_start_size:\n",
    "            continue\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        batch = agent.buffer.sample(batch_size, device = device)\n",
    "        loss_t = Qloss(batch, net, gamma = gamma, device = device)\n",
    "        loss_t.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss += loss_t.item()\n",
    "    \n",
    "    if (agent.env.current_position == agent.env.goal).all():\n",
    "        result = 'won'\n",
    "    else:\n",
    "        result = 'lost'\n",
    "    \n",
    "    if epoch%1000 == 0:\n",
    "        agent.plot_policy_map(net, 'sol_epoch_'+str(epoch)+'.pdf', [0.35,-0.3])\n",
    "    \n",
    "    loss_log.append(loss)\n",
    "    \n",
    "    if (epoch > 2000):\n",
    "        running_loss = np.mean(loss_log[-50:])\n",
    "        if running_loss < best_loss:\n",
    "            best_loss = running_loss\n",
    "            torch.save(net.state_dict(), \"best.torch\")\n",
    "            estop = epoch\n",
    "    \n",
    "    print('Epoch', epoch, '(number of moves ' + str(counter) + ')')\n",
    "    print('Game', result)\n",
    "    print('[' + '#'*(100-int(100*(1 - epoch/num_epochs))) +\n",
    "          ' '*int(100*(1 - epoch/num_epochs)) + ']')\n",
    "    print('\\t Average loss: ' + f'{loss:.5f}')\n",
    "    if (epoch > 2000):\n",
    "        print('\\t Best average loss of the last 50 epochs: ' + f'{best_loss:.5f}' + ', achieved at epoch', estop)\n",
    "    clear_output(wait = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"./results/net.torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epsilon*90, alpha = 0.6, ls = '--', label = 'Epsilon profile (arbitrary unit)', color = 'orangered')\n",
    "plt.plot((np.array(mpm)-np.array(mp))*120, alpha = 0.6, ls = '--',\n",
    "         label = 'Probability difference (arbitrary unit)', color = 'dimgray')\n",
    "plt.plot(loss_log, label = 'Loss', color = 'cornflowerblue')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.savefig('loss.pdf', dpi = 300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show the maze solution and the policy learnt.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net.eval()\n",
    "agent.isgameon = True\n",
    "agent.use_softmax = False\n",
    "_ = agent.env.reset(0)\n",
    "while agent.isgameon:\n",
    "    agent.make_a_move(net, 0)\n",
    "    agent.env.draw('')\n",
    "    clear_output(wait = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.plot_policy_map(net, './results/solution.pdf', [0.35,-0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_net = copy.deepcopy(net)\n",
    "best_net.load_state_dict(torch.load('./results/best_classical.torch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.plot_policy_map(best_net, './results/classical_solution_best.pdf', [0.35,-0.3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
